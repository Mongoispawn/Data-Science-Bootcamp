{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 0:\n",
    "\n",
    "Recall that the logistic regression model's best performance on the test set was 93%.  See what you can do to improve performance.  Suggested avenues of investigation include: Other modeling techniques (SVM?), making more features that take advantage of the spaCy information (include grammar, phrases, POS, etc), making sentence-level features (number of words, amount of punctuation), or including contextual information (length of previous and next sentences, words repeated from one sentence to the next, etc), and anything else your heart desires.  Make sure to design your models on the test set, or use cross_validation with multiple folds, and see if you can get accuracy above 90%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Imports ##############################\n",
    "\n",
    "##### Infrastructure #######\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "####### Models ########\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 17.780986785888672 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "start_time = time.time()\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "# Utility function to create a list of the 1000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    start_time = time.time()\n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 100 == 0:\n",
    "            print(\"Processing row {} - {} seconds\".format(i, (time.time() - start_time)))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0 - 4.768096923828125 seconds\n",
      "Processing row 100 - 183.96259808540344 seconds\n",
      "Processing row 200 - 334.0793879032135 seconds\n",
      "Processing row 300 - 484.36054706573486 seconds\n",
      "Processing row 400 - 632.034982919693 seconds\n",
      "Processing row 500 - 770.7359728813171 seconds\n",
      "Processing row 600 - 911.4912052154541 seconds\n",
      "Processing row 700 - 1068.222242116928 seconds\n",
      "Processing row 800 - 1216.0588638782501 seconds\n",
      "Processing row 900 - 1339.7893288135529 seconds\n",
      "Processing row 1000 - 1484.6506931781769 seconds\n",
      "Processing row 1100 - 1646.1431584358215 seconds\n",
      "Processing row 1200 - 1795.431675195694 seconds\n",
      "Processing row 1300 - 1906.8292698860168 seconds\n",
      "Processing row 1400 - 2034.8620300292969 seconds\n",
      "Processing row 1500 - 2170.50661945343 seconds\n",
      "Processing row 1600 - 2306.1058468818665 seconds\n",
      "Processing row 1700 - 2506.838632106781 seconds\n",
      "Processing row 1800 - 2708.853232383728 seconds\n",
      "Processing row 1900 - 2915.0913486480713 seconds\n",
      "Processing row 2000 - 3148.1815054416656 seconds\n",
      "Processing row 2100 - 3287.5203981399536 seconds\n",
      "Processing row 2200 - 3516.103359222412 seconds\n",
      "Processing row 2300 - 3714.54882478714 seconds\n",
      "Processing row 2400 - 3870.233143091202 seconds\n",
      "Processing row 2500 - 4009.76300740242 seconds\n",
      "Processing row 2600 - 4185.011700391769 seconds\n",
      "Processing row 2700 - 4372.176195859909 seconds\n",
      "Processing row 2800 - 4525.873267412186 seconds\n",
      "Processing row 2900 - 4778.218067884445 seconds\n",
      "Processing row 3000 - 4951.080213308334 seconds\n",
      "Processing row 3100 - 5121.888289690018 seconds\n",
      "Processing row 3200 - 5299.2124354839325 seconds\n",
      "Processing row 3300 - 5453.742264032364 seconds\n",
      "Processing row 3400 - 5628.506831407547 seconds\n",
      "Processing row 3500 - 5773.8506762981415 seconds\n",
      "Processing row 3600 - 5966.964103937149 seconds\n",
      "Processing row 3700 - 6158.036364555359 seconds\n",
      "Processing row 3800 - 6293.126805782318 seconds\n",
      "Processing row 3900 - 6417.612365484238 seconds\n",
      "Processing row 4000 - 6551.373510360718 seconds\n",
      "Processing row 4100 - 6707.7004137039185 seconds\n",
      "Processing row 4200 - 6860.849469423294 seconds\n",
      "Processing row 4300 - 6991.354412555695 seconds\n",
      "Processing row 4400 - 7121.303016662598 seconds\n",
      "Processing row 4500 - 7244.13516998291 seconds\n",
      "Processing row 4600 - 7393.617765426636 seconds\n",
      "Processing row 4700 - 7567.627417564392 seconds\n",
      "Processing row 4800 - 7753.071428775787 seconds\n",
      "Processing row 4900 - 7876.221980571747 seconds\n",
      "Processing row 5000 - 8046.04248380661 seconds\n",
      "Processing row 5100 - 8169.383402109146 seconds\n",
      "Processing row 5200 - 8305.846788167953 seconds\n",
      "Processing row 5300 - 8464.28733587265 seconds\n",
      "-- Execution time: 8499.003977775574 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happiness</th>\n",
       "      <th>seriously</th>\n",
       "      <th>manner</th>\n",
       "      <th>oop</th>\n",
       "      <th>claws</th>\n",
       "      <th>passion</th>\n",
       "      <th>oh</th>\n",
       "      <th>charles</th>\n",
       "      <th>civility</th>\n",
       "      <th>wrong</th>\n",
       "      <th>...</th>\n",
       "      <th>dine</th>\n",
       "      <th>buildings</th>\n",
       "      <th>bite</th>\n",
       "      <th>afford</th>\n",
       "      <th>finger</th>\n",
       "      <th>butter</th>\n",
       "      <th>witness</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  happiness seriously manner oop claws passion oh charles civility wrong  \\\n",
       "0         0         0      0   0     0       0  0       0        0     0   \n",
       "1         0         0      0   0     0       0  0       0        0     0   \n",
       "2         0         0      0   0     0       0  1       0        0     0   \n",
       "3         0         0      0   0     0       0  1       0        0     0   \n",
       "4         0         0      0   0     0       0  0       0        0     0   \n",
       "\n",
       "      ...     dine buildings bite afford finger butter witness recommendation  \\\n",
       "0     ...        0         0    0      0      0      0       0              0   \n",
       "1     ...        0         0    0      0      0      0       0              0   \n",
       "2     ...        0         0    0      0      0      0       0              0   \n",
       "3     ...        0         0    0      0      0      0       0              0   \n",
       "4     ...        0         0    0      0      0      0       0              0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 1563 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "start_time = time.time()\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5318"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The word counts dataframe will have source, sentence and all the words. Need to add other features to this:\n",
    "# Number of words in sentence\n",
    "# Number of unique words in sentence\n",
    "def number_of_words(sentence):\n",
    "    example_words = [token for token in sentence if not token.is_punct]\n",
    "    unique_words = set([token.text for token in example_words])\n",
    "    return len(unique_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Unique words\n",
    "new_df = word_counts\n",
    "new_df['Unique_Words'] = new_df['text_sentence'].apply(lambda x: number_of_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "Y = new_df['text_source']\n",
    "X = new_df.drop(['text_sentence','text_source'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.5059971809387207 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Select The Best Features\n",
    "start_time = time.time()\n",
    "selector = SelectKBest(f_classif, k=50)\n",
    "selector.fit(X,Y)\n",
    "\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "best_features = X[X.columns[idxs_selected]]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Test Train Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austen     3649\n",
       "Carroll    1669\n",
       "Name: text_source, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906641604010025\n",
      "-- Execution time: 72.38328790664673 seconds ---\n"
     ]
    }
   ],
   "source": [
    "################ Logistic Regression ######################\n",
    "start_time = time.time()\n",
    "parameters = {\n",
    "                'penalty':['l1','l2'],\n",
    "                'C':[0.001,0.01,0.1,1,10,100,10000,100000,100000000]\n",
    "               \n",
    "              }\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "grid = GridSearchCV(lr, parameters, scoring='accuracy', cv=5, verbose=0)\n",
    "#Fit the Data\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.score(X_test, y_test))\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Gradient Boost #############################\n",
    "start_time = time.time()\n",
    "parameters = {'subsample':[0.95],\n",
    "              'max_depth':[2,4],\n",
    "              'loss':['exponential'],\n",
    "             'n_estimators':[500]}\n",
    "\n",
    "# Initialize the model.\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "#Create grid and perform 8 cross validation\n",
    "gradient_grid = GridSearchCV(clf, parameters, cv=5, verbose=0)\n",
    "\n",
    "#Fit the Data\n",
    "gradient_grid.fit(X_train, y_train)\n",
    "print(gradient_grid.score(X_test, y_test))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8859649122807017\n"
     ]
    }
   ],
   "source": [
    "print(gradient_grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
