{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill: Playing with layers\n",
    "\n",
    "Now it's your turn. Using the space below, experiment with different hidden layer structures. You can try this on a subset of the data to improve runtime. See how things vary. See what seems to matter the most. Feel free to manipulate other parameters as well.\n",
    "\n",
    "#### Goal: Lets see if we can build a model to classify which department a piece should go into using MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "1. Clean up the data\n",
    "2. Perform Select K best to reduce the amount of features\n",
    "3. Split the data.\n",
    "4. Grid search over lots of parameters and select the best ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Imports #################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Model Infrastructure\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#For selecting features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "\n",
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 2.727679491043091 seconds ---\n"
     ]
    }
   ],
   "source": [
    "######## Bring In Data ################\n",
    "start_time = time.time()\n",
    "artworks = pd.read_csv('https://media.githubusercontent.com/media/MuseumofModernArt/collection/master/Artworks.csv')\n",
    "\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 1.0871126651763916 seconds ---\n"
     ]
    }
   ],
   "source": [
    "######### Clean the Data ##############\n",
    "start_time = time.time()\n",
    "# Select Columns.\n",
    "artworks = artworks[['Artist', 'Nationality', 'Gender', 'Date', 'Department',\n",
    "                    'DateAcquired', 'URL', 'ThumbnailURL', 'Height (cm)', 'Width (cm)']]\n",
    "\n",
    "# Convert URL's to booleans.\n",
    "artworks['URL'] = artworks['URL'].notnull()\n",
    "artworks['ThumbnailURL'] = artworks['ThumbnailURL'].notnull()\n",
    "\n",
    "# Drop films and some other tricky rows.\n",
    "artworks = artworks[artworks['Department']!='Film']\n",
    "artworks = artworks[artworks['Department']!='Media and Performance Art']\n",
    "artworks = artworks[artworks['Department']!='Fluxus Collection']\n",
    "\n",
    "# Drop missing data.\n",
    "artworks = artworks.dropna()\n",
    "\n",
    "# Convert timestamps and dates\n",
    "artworks['DateAcquired'] = pd.to_datetime(artworks.DateAcquired)\n",
    "artworks['YearAcquired'] = artworks.DateAcquired.dt.year\n",
    "\n",
    "# Remove multiple nationalities, genders, and artists.\n",
    "artworks.loc[artworks['Gender'].str.contains('\\) \\('), 'Gender'] = '\\(multiple_persons\\)'\n",
    "artworks.loc[artworks['Nationality'].str.contains('\\) \\('), 'Nationality'] = '\\(multiple_nationalities\\)'\n",
    "artworks.loc[artworks['Artist'].str.contains(','), 'Artist'] = 'Multiple_Artists'\n",
    "\n",
    "# Convert dates to start date, cutting down number of distinct examples.\n",
    "artworks['Date'] = pd.Series(artworks.Date.str.extract(\n",
    "    '([0-9]{4})', expand=False))[:-1]\n",
    "\n",
    "# Final column drops and NA drop.\n",
    "X = artworks.drop(['Department', 'DateAcquired', 'Artist', 'Nationality', 'Date'], 1)\n",
    "\n",
    "# Create dummies separately.\n",
    "artists = pd.get_dummies(artworks.Artist)\n",
    "nationalities = pd.get_dummies(artworks.Nationality)\n",
    "dates = pd.get_dummies(artworks.Date)\n",
    "\n",
    "# Concat with other variables, but artists slows this wayyyyy down so we'll keep it out for now\n",
    "# Removed sparse\n",
    "X = pd.get_dummies(X)\n",
    "X = pd.concat([X, nationalities, dates], axis=1)\n",
    "\n",
    "Y = artworks.Department\n",
    "\n",
    "\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 103881 entries, 0 to 133538\n",
      "Columns: 311 entries, URL to 2017\n",
      "dtypes: bool(2), float64(2), int64(1), uint8(306)\n",
      "memory usage: 33.7 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.476583480834961 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [0 1] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Do some feature reduction\n",
    "start_time = time.time()\n",
    "selector = SelectKBest(f_classif, k=50)\n",
    "selector.fit(X,Y)\n",
    "\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "best_features = X[X.columns[idxs_selected]]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do test train split\n",
    "#Pull out Train, Dev and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(best_features,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prints & Illustrated Books    38197\n",
       "Photography                   16569\n",
       "Architecture & Design          8059\n",
       "Drawings                       7405\n",
       "Painting & Sculpture           2486\n",
       "Name: Department, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Very imbalanced, so need to L2 penalty\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Execution time: 486.2940151691437 seconds ---\n"
     ]
    }
   ],
   "source": [
    "########### Build the Model ################\n",
    "start_time = time.time()\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "\n",
    "parameters = {'hidden_layer_sizes':[(1000,),(100,4)],\n",
    "             'activation':['logistic'],\n",
    "             'solver':['adam'],\n",
    "             'alpha':[0.0001]}\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "grid = grid = GridSearchCV(mlp, parameters, scoring='accuracy', cv=5, verbose=0)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'alpha': 0.0001,\n",
       " 'hidden_layer_sizes': (1000,),\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried different activation: logistic and relu. Logistic was the best\n",
    "# Tried different solver: adam and sgd. Adam was the best\n",
    "# Tried different hidden layer sizes: 1000 and 100. 1000 was the best\n",
    "# Tried hidden_layer_sizes: 1000, and alpha values: 0.0001,0.01,0.1. 0.001 was the best\n",
    "# Tried different hidden layer structure (1000,) and (100,4) 1000, was best\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6188031445531846"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.58 with cross validation and hidden layer size of 1000\n",
    "# 0.62 with activation: logistic, hidden_layer_sizes: 1000, solver: adam (708 seconds)\n",
    "# 0.617 with hidden_layer=1000,, activation: logistic, ,solver: adam, alpha: 0.0001 (1079 seconds)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department                  Architecture & Design  Drawings  \\\n",
      "row_0                                                         \n",
      "Architecture & Design                        1143       110   \n",
      "Drawings                                       51       361   \n",
      "Painting & Sculpture                          170       155   \n",
      "Photography                                   725       657   \n",
      "Prints & Illustrated Books                   1312      1843   \n",
      "\n",
      "Department                  Painting & Sculpture  Photography  \\\n",
      "row_0                                                           \n",
      "Architecture & Design                        111           92   \n",
      "Drawings                                      14           47   \n",
      "Painting & Sculpture                         487          114   \n",
      "Photography                                   90         4925   \n",
      "Prints & Illustrated Books                   384         2018   \n",
      "\n",
      "Department                  Prints & Illustrated Books  \n",
      "row_0                                                   \n",
      "Architecture & Design                              412  \n",
      "Drawings                                           141  \n",
      "Painting & Sculpture                               194  \n",
      "Photography                                       3240  \n",
      "Prints & Illustrated Books                       12369  \n"
     ]
    }
   ],
   "source": [
    "# Create Cross tab\n",
    "y_pred = grid.predict(X_test)\n",
    "print(pd.crosstab(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "     Architecture & Design       0.61      0.34      0.43      3401\n",
      "                  Drawings       0.59      0.12      0.19      3126\n",
      "      Painting & Sculpture       0.43      0.45      0.44      1086\n",
      "               Photography       0.51      0.68      0.59      7196\n",
      "Prints & Illustrated Books       0.69      0.76      0.72     16356\n",
      "\n",
      "               avg / total       0.62      0.62      0.60     31165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
