{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Challenge\n",
    "\n",
    "Do a little scraping or API-calling of your own. Pick a new website and see what you can get out of it. Expect that you'll run into bugs and blind alleys, and rely on your mentor to help you get through.\n",
    "\n",
    "Formally, your goal is to write a scraper that will:\n",
    "\n",
    "1. Return specific pieces of information (rather than just downloading a whole page)\n",
    "2. Iterate over multiple pages/queries\n",
    "3. Save the data to your computer\n",
    "\n",
    "Once you have your data, compute some statistical summaries and/or visualizations that give you some new insights into your scraping topic of interest. Write up a report from scraping code to summary and share it with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Website\n",
    "\n",
    "What if I use glassdoor to get company information to prepare for an interview?\n",
    "1. All interview questions\n",
    "2. Links to the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Imports ##############################\n",
    "# Importing in each cell because of the kernel restarts.\n",
    "import scrapy\n",
    "import re\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Create Crawler ######################\n",
    "\n",
    "class GlassdoorSpider(scrapy.Spider):\n",
    "    # Naming the spider is important if you are running more than one spider of\n",
    "    # this class simultaneously.\n",
    "    name = \"Glassdoor_Simple\"\n",
    "    \n",
    "    # URL(s) to start with.\n",
    "    start_urls = [\n",
    "        'https://www.glassdoor.com/Interview/Facebook-Interview-Questions-E40772.htm?filter.jobTitleFTS=Data+Scientist',\n",
    "    ]\n",
    "\n",
    "    # Use XPath to parse the response we get.\n",
    "    def parse(self, response):\n",
    "       \n",
    "        # Iterate over every review class element on the page.\n",
    "        # Get all the reviews objects for the page\n",
    "        \n",
    "        #Extract the different infomration\n",
    "        for review in response.xpath('//*[starts-with(@id, \"InterviewReview_\")]'):\n",
    "            \n",
    "            \n",
    "            # Yield a dictionary with the values we want.\n",
    "            yield {\n",
    "                # This is the code to choose what we want to extract\n",
    "                # You can modify this with other Xpath expressions to extract other information from the site\n",
    "                'interview_questions': review.xpath('.//div[3]/div/div[2]/div[2]/div/div/ul/li/span/text()').extract(),\n",
    "              'answers' : review.xpath('.//div[3]/div/div[2]/div[2]/div/div/ul/li/span/a/text()').extract(),\n",
    "                'answer_links' : review.xpath('.//div[3]/div/div[2]/div[2]/div/div/ul/li/span/a/@href').extract(),\n",
    "                'helpful': review.xpath('.//div[4]/div/div[3]/span/@data-count').extract_first(),\n",
    "            }\n",
    "\n",
    "        next_page = response.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href').extract()\n",
    "        if next_page:\n",
    "            next_page = next_page[0]\n",
    "            next_page_url = 'https://www.glassdoor.com' + next_page\n",
    "            print(next_page_url)\n",
    "            # Request the next page and recursively parse it the same way we did above\n",
    "            yield scrapy.Request(next_page_url, callback=self.parse)\n",
    "            \n",
    "# Tell the script how to run the crawler by passing in settings.\n",
    "process = CrawlerProcess({\n",
    "    'FEED_FORMAT': 'json',         # Store data in JSON format.\n",
    "    'FEED_URI': 'data.json',  # Name our storage file.\n",
    "    'LOG_ENABLED': False ,          # Turn off logging for now.\n",
    "    'ROBOTSTXT_OBEY': True,\n",
    "    'USER_AGENT': 'BrandynAdderleyCrawler (madderle@gmail.com)',\n",
    "    'AUTOTHROTTLE_ENABLED': True,\n",
    "    'HTTPCACHE_ENABLED': True\n",
    "})\n",
    "\n",
    "# Start the crawler with our spider.\n",
    "process.crawl(GlassdoorSpider)\n",
    "process.start()\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_links</th>\n",
       "      <th>answers</th>\n",
       "      <th>helpful</th>\n",
       "      <th>interview_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[/Interview/Data-challenge-was-very-similar-to...</td>\n",
       "      <td>[23 Answers]</td>\n",
       "      <td>331</td>\n",
       "      <td>[ Data challenge was very similar to the ads a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[/Interview/How-would-you-measure-the-health-o...</td>\n",
       "      <td>[6 Answers, 9 Answers, 7 Answers, 3 Answers, 4...</td>\n",
       "      <td>196</td>\n",
       "      <td>[ How would you measure the health of Mentions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[/Interview/Facebook-has-personal-information-...</td>\n",
       "      <td>[1 Answer, Answer Question]</td>\n",
       "      <td>0</td>\n",
       "      <td>[ Facebook has personal information such as ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[/Interview/Expected-value-combined-with-proba...</td>\n",
       "      <td>[Answer Question]</td>\n",
       "      <td>0</td>\n",
       "      <td>[ Expected value combined with probability   ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[/Interview/They-will-ask-you-to-design-a-very...</td>\n",
       "      <td>[Answer Question]</td>\n",
       "      <td>0</td>\n",
       "      <td>[ They will ask you to design a very simple th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        answer_links  \\\n",
       "0  [/Interview/Data-challenge-was-very-similar-to...   \n",
       "1  [/Interview/How-would-you-measure-the-health-o...   \n",
       "2  [/Interview/Facebook-has-personal-information-...   \n",
       "3  [/Interview/Expected-value-combined-with-proba...   \n",
       "4  [/Interview/They-will-ask-you-to-design-a-very...   \n",
       "\n",
       "                                             answers  helpful  \\\n",
       "0                                       [23 Answers]      331   \n",
       "1  [6 Answers, 9 Answers, 7 Answers, 3 Answers, 4...      196   \n",
       "2                        [1 Answer, Answer Question]        0   \n",
       "3                                  [Answer Question]        0   \n",
       "4                                  [Answer Question]        0   \n",
       "\n",
       "                                 interview_questions  \n",
       "0  [ Data challenge was very similar to the ads a...  \n",
       "1  [ How would you measure the health of Mentions...  \n",
       "2  [ Facebook has personal information such as ge...  \n",
       "3     [ Expected value combined with probability   ]  \n",
       "4  [ They will ask you to design a very simple th...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn into DataFrame\n",
    "glassdoor_df = pd.read_json('data.json', orient='records')\n",
    "glassdoor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_questions = []\n",
    "for row in glassdoor_df['interview_questions']:\n",
    "    #print(len(row))\n",
    "    for question in row:\n",
    "        individual_questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(individual_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
